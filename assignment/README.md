---
layout:     page
title:      Homework 2, Programming Question
permalink:  /AP6c2L5Z4nNd9i4sB86r/hw2-coding/
---

# [CS 4803-7643 Deep Learning - Homework 2][5]

In this homework, we will learn how to implement backpropagation (or backprop) for 
ConvNets. You will begin by writing the forward and
backward passes for convolution and pooling layers, and then go on to train a shallow ConvNet on the CIFAR-10 dataset in Python. Next you’ll learn to use [PyTorch][3], a popular open-source deep learning framework,
and use it to replicate the experiments from before.

This homework is divided into the following parts:

- Implement and train a ConvNet on CIFAR-10 in Python.
- Learn to use PyTorch and replicate previous experiments in PyTorch (ConvNet on CIFAR-10).

Download the starter code [here]({{site.baseurl}}/assets/f20cs7643_hw2_starter.zip).

## Part 1

Starter code for part 1 of the homework is available in the `1_cs231n` folder.

### Setup

Dependencies are listed in the `requirements.txt` file. If working with Anaconda, they should all be installed already.

The dataset is the same as what was used in HW1. Create a symlink to the data you previously downloaded:

```bash
ln -s path_to_hw1/assignment/1_cs231n/cs231n/datasets path_to_hw2/assignment/1_cs231n/cs231n/
```

Otherwise, the data can be redownloaded following the same procedures. 

### Q9.1: Modular Neural Network (4 points)

The IPython notebook `conv_layers.ipynb` will walk you through a modular neural network implementation. You will implement the forward and backward passes of convolution and pooling layers.

### Q9.2: ConvNet on CIFAR-10 (3 points)

The IPython notebook `convnet.ipynb` will walk you through the process of training
a (shallow) convolutional neural network on CIFAR-10. You should get at least a 50% accuracy on the validation set here.

## Part 2

This part is similar to the first part except that you will now be using [PyTorch][3] to 
implement the two-layer neural network. In part 1 you implemented core operations given significant scaffolding code. In part 2 these core operations are given by PyTorch and you simply need to figure out how to use them.

The necessary files for this section are provided in the `2_pytorch` directory.
You will only need to write code in `train.py` and in each file in the `models/` directory.

### Q9.3: ConvNet using PyTorch (3 points)

Implement a shallow convnet. Model code is in `models/convnet.py` and the script to train convnet is  in `run_convnet.sh`. Similar to HW1, we will generate a loss vs. iterations plot for train and val, a validation accuracy vs iterations plot, and visualizations of the weights of the first hidden layer. Use the code from `convnet-classifier.ipynb` and `filter-viz.ipynb`, save the plots as `convnet_lossvstrain.png` and `convnet_valaccuracy.png` and the filters learned as `convnet_gridfilt.png`.

## Deliverables

Submit the deliverables for Q10 by uploading a zip file called `hw2_code.zip` to the `HW2 Code` section on Gradescope.

This zip could be generated by running the following script from the unzipped folder :

```bash
./collect_submission.sh
```
The following files should be included:

1. All the files originally in the 1_cs231n folder (Part 1).
2. All the files originally in the 2_pytorch folder and the ones generated there (Part 2).
3. Model implementations `models/*.py` (Part 2).
4. Training code `train.py` (Part 2).
5. The shell scripts used to train the 2 models (`run_convnet.sh` and `run_mymodel.sh`) (Part 2).
6. Learning curves (loss) and validation accuracy plots (Part 2).
7. The version of `filter-viz.ipynb` used to show filter visualizations (Part 2).
8. Log files for each model with test accuracy reported at the bottom (Part 2).

Note that the PDF being uploaded to the `HW2` section must also contain the Jupyter notebooks and generated images. Mark them according to the right sub-questions on Gradescope. You could append the PDFs generated from the Jupyter notebooks and the generated images `convnet_filt.png` and `convnet_gridfilt.png` to the one containing your theory solutions and upload the resulting PDF on Gradescope.

### Q9.4 Experiment (5 pts required + 5 pts extra credit for 4803 and 7643)

Experiment and try to get the best performance that you can on CIFAR-10 using a ConvNet.
Submit your entry on a challenge hosted on [EvalAI](https://evalai.cloudcv.org/web/challenges/challenge-page/684/overview). The website will show a live leader board, so you can see how your implementation is doing compared to others. In order to prevent you from overfitting to the test data, the website limits the number of submissions to 3 per day, and only shows the leaderboard computed on 10% of the test data (so final standings may change). You will receive 5 pts regular credit for submitting something that beats chance, 5 points extra credit for beating the instructor/TA’s implementation.

Evaluate your best model using `test.py` and upload the `predictions.csv` file on EvalAI. To participate, you will have to sign up on EvalAI using your gatech.edu email. Please tell us in your writeup `extra.md` what you tried. 

For getting better performance, some things you can try:  
- Filter size: In part 1 we used 7x7; this makes pretty pictures but smaller filters may be more efficient
- Number of filters: In part 1 we used 32 filters. Do more or fewer do better?
- Network depth: Some good architectures to try include:
    - [conv-relu-pool]xN - conv - relu - [affine]xM - [softmax or SVM]
    - [conv-relu-pool]xN - [affine]xM - [softmax or SVM]
    - [conv-relu-conv-relu-pool]xN - [affine]xM - [softmax or SVM]
- Alternative update steps: AdaGrad, AdaDelta, Adam

**Deliverables**

Be sure to include the following in the `hw2_code.zip` file

- Model definition file `models/mymodel.py`
- Training log, loss plot, and validation accuracy plot as above
- List and describe all that you tried in a text file called `extra.md`
- Name, Email ID, and Best Accuracy in `extra.md`

References:

1. [CS231n Convolutional Neural Networks for Visual Recognition][2]

[2]: http://cs231n.stanford.edu/
[3]: http://pytorch.org/
[4]: http://bvlc.eecs.berkeley.edu/
[5]: https://www.cc.gatech.edu/classes/AY2021/cs7643_fall/
[8]: https://github.com/pytorch/examples
[9]: https://developer.nvidia.com/cudnn
[10]: https://github.com/pytorch/pytorch#installation
[11]: https://github.com/pytorch/pytorch
[12]: http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html


---

&#169; 2020 Georgia Tech
